"""
Comprehensive security tests for the chat system.
Tests rate limiting, content validation, access control, and file upload security.
"""
import pytest
import asyncio
import json
from uuid import uuid4, UUID
from unittest.mock import Mock, AsyncMock, patch
from fastapi.testclient import TestClient
from fastapi import WebSocket
import redis.asyncio as redis

from src.core.security.rate_limiter import (
    RedisRateLimiter, RateLimitType, RateLimitExceeded, RateLimitConfig
)\nfrom src.core.security.content_security import (\n    ContentValidator, FileUploadSecurityValidator, ContentSecurityError\n)\nfrom src.core.security.websocket_security import (\n    WebSocketAuthenticator, WebSocketConnectionManager, WebSocketSecurityError\n)\nfrom src.core.security.sentry_security import SentrySecurityMonitor\n\nclass TestRateLimiter:\n    \"\"\"Test rate limiting functionality\"\"\"\n    \n    @pytest.fixture\n    async def redis_mock(self):\n        return Mock(spec=redis.Redis)\n    \n    @pytest.fixture\n    def rate_limiter(self, redis_mock):\n        return RedisRateLimiter(redis_mock)\n    \n    @pytest.mark.asyncio\n    async def test_rate_limit_allows_within_limit(self, rate_limiter, redis_mock):\n        \"\"\"Test that requests within limit are allowed\"\"\"\n        # Mock Redis responses for sliding window check\n        redis_mock.pipeline.return_value.__aenter__.return_value.execute = AsyncMock(\n            return_value=[None, 5, None, None]  # 5 requests in window\n        )\n        redis_mock.get.return_value = None  # No existing bucket\n        redis_mock.setex = AsyncMock()\n        \n        allowed, retry_after = await rate_limiter.is_allowed(\n            \"user123\", RateLimitType.MESSAGE_SEND\n        )\n        \n        assert allowed is True\n        assert retry_after == 0\n    \n    @pytest.mark.asyncio\n    async def test_rate_limit_blocks_over_limit(self, rate_limiter, redis_mock):\n        \"\"\"Test that requests over limit are blocked\"\"\"\n        # Mock Redis responses for over limit\n        redis_mock.pipeline.return_value.__aenter__.return_value.execute = AsyncMock(\n            return_value=[None, 61, None, None]  # 61 requests (over limit of 60)\n        )\n        redis_mock.zrange.return_value = [(b\"timestamp\", 1000)]\n        \n        allowed, retry_after = await rate_limiter.is_allowed(\n            \"user123\", RateLimitType.MESSAGE_SEND\n        )\n        \n        assert allowed is False\n        assert retry_after > 0\n    \n    @pytest.mark.asyncio\n    async def test_different_rate_limits_independent(self, rate_limiter, redis_mock):\n        \"\"\"Test that different rate limit types are independent\"\"\"\n        redis_mock.pipeline.return_value.__aenter__.return_value.execute = AsyncMock(\n            return_value=[None, 1, None, None]\n        )\n        redis_mock.get.return_value = None\n        redis_mock.setex = AsyncMock()\n        \n        # Both should be allowed independently\n        msg_allowed, _ = await rate_limiter.is_allowed(\n            \"user123\", RateLimitType.MESSAGE_SEND\n        )\n        ws_allowed, _ = await rate_limiter.is_allowed(\n            \"user123\", RateLimitType.WEBSOCKET_CONNECT\n        )\n        \n        assert msg_allowed is True\n        assert ws_allowed is True\n\nclass TestContentSecurity:\n    \"\"\"Test content validation and sanitization\"\"\"\n    \n    def test_sanitize_safe_text(self):\n        \"\"\"Test sanitization of safe text content\"\"\"\n        validator = ContentValidator()\n        result = validator.validate_and_sanitize_message(\n            \"Hello world! This is a safe message.\",\n            \"text\"\n        )\n        \n        assert \"Hello world!\" in result[\"content\"]\n        assert result[\"security_score\"] >= 0.9\n    \n    def test_block_xss_attempts(self):\n        \"\"\"Test blocking of XSS attempts\"\"\"\n        validator = ContentValidator()\n        \n        malicious_inputs = [\n            \"<script>alert('xss')</script>\",\n            \"javascript:alert('xss')\",\n            \"<img src=x onerror=alert('xss')>\",\n            \"<iframe src='javascript:alert(1)'></iframe>\"\n        ]\n        \n        for malicious_input in malicious_inputs:\n            with pytest.raises(ContentSecurityError):\n                validator.validate_and_sanitize_message(\n                    malicious_input, \"html\", user_id=uuid4()\n                )\n    \n    def test_sanitize_html_content(self):\n        \"\"\"Test HTML sanitization keeps safe tags\"\"\"\n        validator = ContentValidator()\n        safe_html = \"<p>Hello <strong>world</strong>!</p>\"\n        \n        result = validator.validate_and_sanitize_message(safe_html, \"html\")\n        \n        assert \"<p>\" in result[\"content\"]\n        assert \"<strong>\" in result[\"content\"]\n        assert \"<script\" not in result[\"content\"]\n    \n    def test_message_length_limit(self):\n        \"\"\"Test message length limits\"\"\"\n        validator = ContentValidator()\n        long_message = \"x\" * 5000  # Exceeds MAX_MESSAGE_LENGTH\n        \n        with pytest.raises(ContentSecurityError, match=\"Message too long\"):\n            validator.validate_and_sanitize_message(long_message, \"text\")\n    \n    def test_link_count_limit(self):\n        \"\"\"Test link count limits\"\"\"\n        validator = ContentValidator()\n        many_links = \" \".join([f\"https://example{i}.com\" for i in range(10)])\n        \n        with pytest.raises(ContentSecurityError, match=\"Too many links\"):\n            validator.validate_and_sanitize_message(many_links, \"text\")\n    \n    def test_metadata_sanitization(self):\n        \"\"\"Test metadata sanitization\"\"\"\n        validator = ContentValidator()\n        metadata = {\n            \"safe_key\": \"safe_value\",\n            \"<script>alert</script>\": \"malicious_key\",\n            \"normal_key\": \"<script>alert('xss')</script>\"\n        }\n        \n        result = validator.validate_and_sanitize_message(\n            \"test message\", \"text\", metadata\n        )\n        \n        sanitized_metadata = result[\"metadata\"]\n        assert \"safe_key\" in sanitized_metadata\n        assert \"<script>\" not in str(sanitized_metadata)\n\nclass TestFileUploadSecurity:\n    \"\"\"Test file upload security validation\"\"\"\n    \n    @pytest.fixture\n    def file_validator(self):\n        return FileUploadSecurityValidator()\n    \n    @pytest.mark.asyncio\n    async def test_dangerous_file_extension_blocked(self, file_validator):\n        \"\"\"Test that dangerous file extensions are blocked\"\"\"\n        mock_file = Mock()\n        mock_file.filename = \"malicious.exe\"\n        mock_file.read.return_value = b\"fake exe content\"\n        mock_file.seek = Mock()\n        \n        with pytest.raises(ContentSecurityError, match=\"Dangerous file extension\"):\n            await file_validator.validate_file_upload(mock_file, uuid4())\n    \n    @pytest.mark.asyncio\n    async def test_file_size_limit(self, file_validator):\n        \"\"\"Test file size limits\"\"\"\n        mock_file = Mock()\n        mock_file.filename = \"large.jpg\"\n        mock_file.read.return_value = b\"x\" * (10 * 1024 * 1024)  # 10MB\n        mock_file.seek = Mock()\n        mock_file.content_type = \"image/jpeg\"\n        \n        # Mock magic to return correct MIME type\n        with patch('magic.Magic') as mock_magic:\n            mock_magic.return_value.from_buffer.return_value = \"image/jpeg\"\n            \n            with pytest.raises(ContentSecurityError, match=\"File too large\"):\n                await file_validator.validate_file_upload(mock_file, uuid4())\n    \n    @pytest.mark.asyncio\n    async def test_mime_type_validation(self, file_validator):\n        \"\"\"Test MIME type validation\"\"\"\n        mock_file = Mock()\n        mock_file.filename = \"test.jpg\"\n        mock_file.content_type = \"image/jpeg\"\n        mock_file.read.return_value = b\"\\x89PNG\\r\\n\\x1a\\n\"  # PNG header, not JPEG\n        mock_file.seek = Mock()\n        \n        with patch('magic.Magic') as mock_magic:\n            mock_magic.return_value.from_buffer.return_value = \"image/png\"\n            \n            with pytest.raises(ContentSecurityError, match=\"MIME type mismatch\"):\n                await file_validator.validate_file_upload(mock_file, uuid4())\n    \n    @pytest.mark.asyncio\n    async def test_malicious_file_content(self, file_validator):\n        \"\"\"Test detection of malicious content in files\"\"\"\n        mock_file = Mock()\n        mock_file.filename = \"test.jpg\"\n        mock_file.content_type = \"image/jpeg\"\n        mock_file.read.return_value = b\"JFIF\\x00\\x00<script>alert('xss')</script>\"\n        mock_file.seek = Mock()\n        \n        with patch('magic.Magic') as mock_magic:\n            mock_magic.return_value.from_buffer.return_value = \"image/jpeg\"\n            \n            with pytest.raises(ContentSecurityError, match=\"malicious content\"):\n                await file_validator.validate_file_upload(mock_file, uuid4())\n\nclass TestWebSocketSecurity:\n    \"\"\"Test WebSocket security measures\"\"\"\n    \n    @pytest.fixture\n    def ws_authenticator(self):\n        return WebSocketAuthenticator(\"test-secret-key\")\n    \n    @pytest.fixture\n    def redis_mock(self):\n        return Mock(spec=redis.Redis)\n    \n    @pytest.fixture\n    def ws_manager(self, redis_mock):\n        rate_limiter = RedisRateLimiter(redis_mock)\n        return WebSocketConnectionManager(redis_mock, rate_limiter)\n    \n    @pytest.mark.asyncio\n    async def test_websocket_authentication_no_token(self, ws_authenticator, redis_mock):\n        \"\"\"Test WebSocket authentication fails without token\"\"\"\n        mock_websocket = Mock(spec=WebSocket)\n        mock_websocket.url.query = \"\"\n        mock_websocket.headers = {}\n        \n        with pytest.raises(WebSocketSecurityError, match=\"No authentication token\"):\n            await ws_authenticator.authenticate_websocket(mock_websocket, redis_mock)\n    \n    @pytest.mark.asyncio\n    async def test_websocket_connection_limit_per_user(self, ws_manager, redis_mock):\n        \"\"\"Test per-user connection limits\"\"\"\n        user_id = uuid4()\n        user_info = {'user_id': user_id, 'tenant_id': uuid4(), 'permissions': []}\n        \n        # Mock rate limiter to allow connections\n        ws_manager.rate_limiter.is_allowed = AsyncMock(return_value=(True, 0))\n        \n        # Add maximum allowed connections\n        for i in range(ws_manager.MAX_CONNECTIONS_PER_USER):\n            mock_ws = Mock(spec=WebSocket)\n            mock_ws.accept = AsyncMock()\n            connection_id = f\"conn_{i}\"\n            \n            # First connections should succeed\n            result = await ws_manager.add_connection(\n                mock_ws, connection_id, user_info, \"127.0.0.1\"\n            )\n            assert result is True\n        \n        # One more should fail\n        mock_ws_extra = Mock(spec=WebSocket)\n        mock_ws_extra.close = AsyncMock()\n        \n        result = await ws_manager.add_connection(\n            mock_ws_extra, \"extra_conn\", user_info, \"127.0.0.1\"\n        )\n        assert result is False\n        mock_ws_extra.close.assert_called_once()\n    \n    @pytest.mark.asyncio\n    async def test_message_rate_limiting(self, ws_manager, redis_mock):\n        \"\"\"Test message rate limiting\"\"\"\n        user_id = uuid4()\n        connection_id = \"test_conn\"\n        \n        # Set up connection metadata\n        ws_manager.connection_metadata[connection_id] = {\n            'user_id': user_id,\n            'tenant_id': uuid4(),\n            'ip_address': '127.0.0.1',\n            'connected_at': '2023-01-01T00:00:00',\n            'last_activity': '2023-01-01T00:00:00',\n            'permissions': [],\n            'message_count': 0\n        }\n        \n        # Mock rate limiter to deny after limit\n        ws_manager.rate_limiter.is_allowed = AsyncMock(\n            side_effect=[\n                (True, 0),  # First message allowed\n                RateLimitExceeded(RateLimitType.MESSAGE_SEND, 60)  # Second denied\n            ]\n        )\n        \n        # First message should work\n        await ws_manager.track_message_activity(connection_id, \"send_message\")\n        \n        # Second should raise rate limit exception\n        ws_manager.active_connections[connection_id] = Mock(spec=WebSocket)\n        ws_manager.active_connections[connection_id].close = AsyncMock()\n        \n        with pytest.raises(RateLimitExceeded):\n            await ws_manager.track_message_activity(connection_id, \"send_message\")\n\nclass TestSentryIntegration:\n    \"\"\"Test Sentry security monitoring integration\"\"\"\n    \n    @pytest.fixture\n    def sentry_monitor(self):\n        return SentrySecurityMonitor(\n            \"https://fake-dsn@sentry.io/123456\",\n            environment=\"test\"\n        )\n    \n    @patch('sentry_sdk.capture_message')\n    def test_track_security_event(self, mock_capture, sentry_monitor):\n        \"\"\"Test security event tracking\"\"\"\n        from src.core.security.sentry_security import SecurityEventType, SecurityEventLevel\n        \n        sentry_monitor.track_security_event(\n            SecurityEventType.RATE_LIMIT_EXCEEDED,\n            SecurityEventLevel.WARNING,\n            uuid4(),\n            {\"test\": \"data\"}\n        )\n        \n        mock_capture.assert_called_once()\n        args, kwargs = mock_capture.call_args\n        assert \"Security Event: rate_limit_exceeded\" in args[0]\n        assert kwargs['level'] == 'warning'\n    \n    @patch('sentry_sdk.capture_message')\n    def test_track_malicious_content(self, mock_capture, sentry_monitor):\n        \"\"\"Test malicious content tracking\"\"\"\n        user_id = uuid4()\n        \n        sentry_monitor.track_malicious_content(\n            user_id,\n            \"html\",\n            \"<script>\",\n            \"<script>alert('xss')</script>\",\n            uuid4()\n        )\n        \n        mock_capture.assert_called_once()\n\nclass TestIntegrationSecurity:\n    \"\"\"Integration tests for security measures\"\"\"\n    \n    @pytest.mark.asyncio\n    async def test_end_to_end_message_security(self):\n        \"\"\"Test complete message security pipeline\"\"\"\n        # This would test the entire flow from WebSocket message\n        # through rate limiting, content validation, and storage\n        \n        # Mock all dependencies\n        redis_mock = Mock()\n        db_mock = Mock()\n        user_id = uuid4()\n        \n        # Create message with potential XSS\n        malicious_message = {\n            \"type\": \"send_message\",\n            \"room_id\": str(uuid4()),\n            \"content\": \"Hello <script>alert('xss')</script>\",\n            \"content_type\": \"html\"\n        }\n        \n        # This should be blocked by content security\n        validator = ContentValidator()\n        \n        with pytest.raises(ContentSecurityError):\n            validator.validate_and_sanitize_message(\n                malicious_message[\"content\"],\n                malicious_message[\"content_type\"],\n                user_id=user_id\n            )\n    \n    @pytest.mark.asyncio\n    async def test_rate_limit_across_operations(self):\n        \"\"\"Test that rate limits work across different operations\"\"\"\n        redis_mock = Mock()\n        rate_limiter = RedisRateLimiter(redis_mock)\n        user_id = str(uuid4())\n        \n        # Mock Redis to simulate hitting rate limits\n        redis_mock.pipeline.return_value.__aenter__.return_value.execute = AsyncMock(\n            return_value=[None, 100, None, None]  # Over limit\n        )\n        redis_mock.zrange.return_value = [(b\"timestamp\", 1000)]\n        \n        # Should be blocked for message sending\n        allowed, _ = await rate_limiter.is_allowed(\n            user_id, RateLimitType.MESSAGE_SEND\n        )\n        assert allowed is False\n        \n        # Should still work for different operation type\n        redis_mock.pipeline.return_value.__aenter__.return_value.execute = AsyncMock(\n            return_value=[None, 1, None, None]  # Under limit\n        )\n        \n        allowed, _ = await rate_limiter.is_allowed(\n            user_id, RateLimitType.TYPING_INDICATOR\n        )\n        # This might still be blocked depending on implementation\n\n# Performance and stress tests\nclass TestSecurityPerformance:\n    \"\"\"Test security performance under load\"\"\"\n    \n    @pytest.mark.asyncio\n    async def test_rate_limiter_performance(self):\n        \"\"\"Test rate limiter performance with many requests\"\"\"\n        redis_mock = Mock()\n        redis_mock.pipeline.return_value.__aenter__.return_value.execute = AsyncMock(\n            return_value=[None, 1, None, None]\n        )\n        redis_mock.get.return_value = None\n        redis_mock.setex = AsyncMock()\n        \n        rate_limiter = RedisRateLimiter(redis_mock)\n        user_id = str(uuid4())\n        \n        # Time multiple rate limit checks\n        import time\n        start_time = time.time()\n        \n        for _ in range(100):\n            await rate_limiter.is_allowed(user_id, RateLimitType.MESSAGE_SEND)\n        \n        end_time = time.time()\n        duration = end_time - start_time\n        \n        # Should complete 100 checks in reasonable time\n        assert duration < 1.0  # Less than 1 second\n    \n    def test_content_validator_performance(self):\n        \"\"\"Test content validator performance with large messages\"\"\"\n        validator = ContentValidator()\n        \n        # Large but safe message\n        large_message = \"Safe content. \" * 200  # About 2800 characters\n        \n        import time\n        start_time = time.time()\n        \n        for _ in range(100):\n            validator.validate_and_sanitize_message(large_message, \"text\")\n        \n        end_time = time.time()\n        duration = end_time - start_time\n        \n        # Should complete 100 validations in reasonable time\n        assert duration < 2.0  # Less than 2 seconds